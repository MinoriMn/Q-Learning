{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q学習用クラス\n",
    "## Q data\n",
    "`Q[x座標][y座標][\"上\",\"下\",\"右\",\"左\",\"B\"]`\n",
    "\n",
    "`\"上\",\"下\",\"右\",\"左\"`->Q値\n",
    "\n",
    "`\"B\"`->その時点での最大Q値の方向(\"上\",\"下\",\"右\",\"左\", \"\")\n",
    "\n",
    "QData側では壁と道の区別はしない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "import random\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行動\n",
    "class Action(Enum):\n",
    "    UP = 1\n",
    "    DOWN = 2\n",
    "    LEFT = 4\n",
    "    RIGHT = 8\n",
    "    BEST = 64\n",
    "    \n",
    "    @staticmethod\n",
    "    def action_to_transition(action):\n",
    "        if action == Action.UP:\n",
    "            dx = 0\n",
    "            dy = -1\n",
    "        elif action == Action.DOWN:\n",
    "            dx = 0\n",
    "            dy = 1\n",
    "        elif action == Action.LEFT:\n",
    "            dx = -1\n",
    "            dy = 0\n",
    "        elif action == Action.RIGHT:\n",
    "            dx = 1\n",
    "            dy = 0\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q値更新\n",
    "class QUpdate(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def update_QData(self, parameter):\n",
    "        pass\n",
    "    \n",
    "class QLearning(QUpdate):\n",
    "    def update_QData(self, parameter):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 行動選択方法\n",
    "class ActionSelect(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def get_next_state(self, qData):\n",
    "        pass\n",
    "    \n",
    "class EpGreedy(ActionSelect):\n",
    "    def __init__(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def get_next_state(self, qData):\n",
    "        if (qData[Action.BEST] == 0) or (random.random() <= self.epsilon):\n",
    "            return random.choice(list(Action))\n",
    "        else:\n",
    "            best = qData[Action.BEST]\n",
    "            actions = []\n",
    "            if best & 1 > 0: \n",
    "                actions.append(Action.UP)\n",
    "            elif best & 2 > 0: \n",
    "                actions.append(Action.DOWN)\n",
    "            elif best & 4 > 0: \n",
    "                actions.append(Action.LEFT)\n",
    "            elif best & 8 > 0: \n",
    "                actions.append(Action.RIGHT)\n",
    "            return actions[random.randrange(len(actions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReinforcementLearning:\n",
    "    PATH = 0 #道\n",
    "    WALL = 1 #壁\n",
    "    \n",
    "    # rewardData ... 報酬データ[x][y] = 報酬値\n",
    "    def __init__(self, width, height, rewardData, actionSelect):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.qData = []\n",
    "        self.rewardData = rewardData\n",
    "        self.actionSelect = actionSelect\n",
    "\n",
    "        for x in range(0, self.width):\n",
    "            qRow = []\n",
    "            for y in range(0, self.height):\n",
    "                qRow.append({Action.UP : 0, Action.DOWN : 0, Action.RIGHT : 0, Action.LEFT : 0, Action.BEST : 0})\n",
    "            self.qData.append(qRow)\n",
    "        \n",
    "    def get_next_state(self, x, y):\n",
    "        while True:\n",
    "            action = self.actionSelect.get_next_state(qData[x][y])\n",
    "            dx, dy = Action.action_to_transition(action)\n",
    "            _x = x + dx\n",
    "            _y = y + dy\n",
    "            if is_in_maze(_x, _y):\n",
    "                break\n",
    "        return _x, _y\n",
    "        \n",
    "    def update_QData(self, parameter):\n",
    "        pass\n",
    "        \n",
    "    def is_in_maze(self, x, y):\n",
    "        if (x < 0) or (y < 0) or (x > self.width) or (y > self.height):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
